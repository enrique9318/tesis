{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nA Multilayer Perceptron implementation example using TensorFlow library.\\nThis example is using the MNIST database of handwritten digits\\n(http://yann.lecun.com/exdb/mnist/)\\n\\nAuthor: Aymeric Damien\\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "A Multilayer Perceptron implementation example using TensorFlow library.\n",
    "This example is using the MNIST database of handwritten digits\n",
    "(http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sess = tf.InteractiveSession()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 2  4  6]\n",
      " [ 3  6  9]\n",
      " [ 4  8 12]]\n",
      "[ 2.5  5.   7.5]\n",
      "[[-1.5 -3.  -4.5]\n",
      " [-0.5 -1.  -1.5]\n",
      " [ 0.5  1.   1.5]\n",
      " [ 1.5  3.   4.5]]\n",
      "[  1.25   5.    11.25]\n",
      "[[-1.2        -0.6        -0.4       ]\n",
      " [-0.4        -0.2        -0.13333333]\n",
      " [ 0.4         0.2         0.13333333]\n",
      " [ 1.2         0.6         0.4       ]]\n"
     ]
    }
   ],
   "source": [
    "entrada = np.array([[1,2,3], [2, 4, 6], [3, 6, 9], [4, 8, 12]])\n",
    "salida = [1, 2, 3, 4]\n",
    "print(entrada)\n",
    "total_examples = entrada.shape[0]\n",
    "# Normalizando\n",
    "mean = np.mean(entrada, axis = 0)\n",
    "entrada = entrada - media\n",
    "print(mean)\n",
    "print(entrada)\n",
    "std2 = np.mean(entrada**2, axis = 0)\n",
    "print(std2)\n",
    "entrada/= std2\n",
    "print(entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46657, 132)\n",
      "(46657, 2)\n",
      "[[ 0.03205161 -0.13617751  0.0358077  ..., -0.15070282  0.04516304\n",
      "  -0.15473172]\n",
      " [ 0.00125132 -0.01384508  0.00230095 ..., -0.00330612  0.01596701\n",
      "  -0.00418618]\n",
      " [-0.00086877  0.12326346 -0.00021004 ...,  0.08616855  0.00336041\n",
      "   0.09433222]\n",
      " ..., \n",
      " [ 0.0144234   0.0242979   0.0147555  ...,  0.03101431  0.02119768\n",
      "   0.03523143]\n",
      " [-0.00855412 -0.04962559 -0.00680894 ..., -0.0474899   0.00606121\n",
      "  -0.04585915]\n",
      " [ 0.01952733  0.02416904  0.01850191 ..., -0.0010919   0.00775349\n",
      "  -0.00351982]]\n",
      "[[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " ..., \n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "entrada = np.genfromtxt('C:\\\\Users\\\\hp\\\\Documents\\\\TFG\\\\Notebooks\\\\entrada.csv', delimiter=',').T\n",
    "total_examples = entrada.shape[0]\n",
    "# Normalizando\n",
    "mean = np.mean(entrada, axis = 0)\n",
    "entrada = entrada - mean\n",
    "std2 = np.mean(entrada**2, axis = 0)\n",
    "entrada/= std2\n",
    "\n",
    "salida = np.genfromtxt('C:\\\\Users\\\\hp\\\\Documents\\\\TFG\\\\Notebooks\\\\salidafac43.csv', delimiter = ',')\n",
    "# 1hot encoding\n",
    "salida = pd.get_dummies(list(salida)).values\n",
    "\n",
    "print(entrada.shape)\n",
    "print(salida.shape)\n",
    "\n",
    "\n",
    "m_train = int(total_examples * 0.75)\n",
    "m_test = total_examples - m_train\n",
    "X_train = entrada[0:(m_train),:]\n",
    "Y_train = salida[0:(m_train), :]\n",
    "X_test = entrada[m_train:total_examples,:]\n",
    "Y_test = salida[m_train:total_examples, :]\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, Y_train = shuffle(X_train, Y_train, random_state=10)\n",
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33437  1555]\n",
      "[10856   809]\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(Y_train, axis = 0))\n",
    "print(np.sum(Y_test, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 50\n",
    "batch_size = 10000\n",
    "display_step = 4\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 132 # 66 * 2 features\n",
    "n_classes = 2  # abierto o cerrado\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float32\", [None, n_input])\n",
    "y = tf.placeholder(\"float32\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 3.588157018\n",
      "Epoch: 0005 cost= 1.240242561\n",
      "Epoch: 0009 cost= 0.604068021\n",
      "Epoch: 0013 cost= 0.284048448\n",
      "Epoch: 0017 cost= 0.164325977\n",
      "Epoch: 0021 cost= 0.112331383\n",
      "Epoch: 0025 cost= 0.081791018\n",
      "Epoch: 0029 cost= 0.063280030\n",
      "Epoch: 0033 cost= 0.051531953\n",
      "Epoch: 0037 cost= 0.042417211\n",
      "Epoch: 0041 cost= 0.035144885\n",
      "Epoch: 0045 cost= 0.029989285\n",
      "Epoch: 0049 cost= 0.026129655\n",
      "Optimization Finished!\n",
      "Accuracy: 0.924989\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(m_train/batch_size)\n",
    "        # Loop over all batches\n",
    "        for i in range(total_batch):\n",
    "            batch_x = X_train[i * batch_size: ((i+1)*batch_size),]\n",
    "            batch_y = Y_train[i * batch_size: ((i+1)*batch_size),]\n",
    "            #batch_y = batch_y.reshape((-1,1))\n",
    "            # Run optimization op (backprop) and cost op (to get loss value)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x,\n",
    "                                                          y: batch_y})\n",
    "            # Compute average loss\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    #Y_test = Y_test.reshape((-1,1))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: X_test, y: Y_test}))\n",
    "    predict = tf.argmax(pred, 1)\n",
    "    predd = predict.eval({x: X_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['shuffle', 'mean']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10647   209]\n",
      " [  666   143]]\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score,confusion_matrix,classification_report\n",
    "\n",
    "lab=pd.DataFrame(Y_test).idxmax(1).values\n",
    "cnf_matrix = confusion_matrix(lab,predd)\n",
    "print(cnf_matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print( predd )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N=np.linspace(1,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(min(lab),max(lab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11665,) (11665,)\n"
     ]
    }
   ],
   "source": [
    "print(lab.shape,predd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A=tf.contrib.metrics.confusion_matrix(lab,predd) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10647   209]\n",
      " [  666   143]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "cnf_matrix = confusion_matrix(lab,predd)\n",
    "np.set_printoptions(precision=2)\n",
    "print(cnf_matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
